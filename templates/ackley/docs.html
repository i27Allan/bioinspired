{% extends 'base.html' %}
{% load static %}

{% block title %}Ackley docs (Portuguese){% endblock %}
{% block appname %}Ackley | docs{% endblock %}

{% block content %}
    <h1>A função de Ackley</h1>
    <div>
        <img src="{% static 'imgs/ackley.png' %}">
        <img src="{% static 'imgs/ackley_plot.png' %}">
    </div>
    <p>
        Função de <i><strong>d</strong></i> dimensões, com uma enorme quantidade de pontos que são
        <a href="https://en.wikipedia.org/wiki/Local_optimum">ótimos locais</a> e um ponto que é ótimo local.
        Essa característica a torna ideal para testar o desempenho de algoritmos de
        <a href="https://en.wikipedia.org/wiki/Evolution_strategy">Estratégias Evolucionárias</a>. E é justamente essa
        a proposta do Bioinspired | Ackley: Fornecer uma interface para testes e checagem do comportamento de um
        algoritmo de estratégia evolucionária com base na variação de seus parâmetros e heurísticas.
        <br><br>
        <i>Para manter o ponto de mínimo global igual a zero, neste sistema os valores 20, 0.2 e 2&pi; são adotados para as
        constantes <strong>a</strong>, <strong>b</strong> e <strong>c</strong>, respectivamente.</i>
    </p>
    <br>
    <hr style="color: black">
    <br>
    <h2>Parâmetros do sistema:</h2>
    <h3>Number of Dimensions</h3>
        <p>
            Representa o valor <i><strong>d</strong></i> da função. Determina o número de varíveis livres
            (<i><strong>xi</strong></i>) da função.
            Ou seja, se <i><strong>d</strong></i> é o valor passado em "Number of Dimensions", então
            0 &lt; i &le; <i><strong>d</strong></i>, i &isin; &#8484;.
        </p>
    <h3>Survivor Selection</h3>
    <p>Em algoritmos estratégias evolucionárias, a seleção dos sobreviventes de cada geração pode ser feita de duas maneiras diferentes:</p>
    <ul>
        <li>
            (&mu; + &lambda;): Neste tipo de seleção, &mu; pais irão gerar &lambda; filhos e os &mu; melhores indivíduos do conjunto
            de pais e filhos (&mu; + &lambda;) são escolhidos para a próxima geração.
        </li>
        <li>
            (&mu;,&lambda;): Neste tipo de seleção, &mu; pais irão gerar &lambda; filhos e os &mu; melhores indivíduos do conjunto
            de filhos (&lambda;) são escolhidos para a próxima geração (repare que a cada geração, o conjunto de pais da geração anterior
            é completamente "esquecido".
        </li>
    </ul>
    <p>
        Repare que &mu; é o tamanho da população, pois toda geração, independente do processo de seleção de sobreviventes, sempre terá &mu; indivíduos.
        O processo de seleção de sobreviventes só modifica a forma com a qual os &lambda; filhos recém-gerados são inseridos na população.
        Para alcançar um bom desempenho na resolução do problema através de algoritmos evolucionários é ideal que &lambda; &gt; &mu;, pois desta forma
        se garante que a geração de filhos terá relevância suficiente para melhorar a população da geração de pais. Além do mais, quanto maior o &lambda;,
        maior é a probabilidade de gerar bons indivíduos a cada iteração. Testes mostram que a melhor proporção &mu;/&lambda; é equivalente a 1/7.
    </p>
    <h3>Mi size (&mu;)</h3>
        Define o número de pais de cada geração (que é o mesmo que o número de indivíduos na população).
    <h3>Lambda size (&lambda;)</h3>
        Define quantos filhos são gerados em cada geração.
    <h3>Crossover operator</h3>
    <h5>Quanto à heurística:</h5>
    <ul>
        <li>Uniform: O i-ésimo gene do genótipo do novo indivíduo é uma cópia do i-ésimo gene do pai1 ou do i-ésimo gene do pai2, com probabilidade de 50% de escolha para cada pai.</li>
        <li>Intermediary: O i-ésimo gene do genótipo do novo indivíduo recebe o valor ((1-&delta;) &#215; i-ésimo_gene_pai1) &plus; (&delta; &#215; i-ésimo_gene_pai_2), onde &delta; é o fator de ponderação
         e consiste num valor real entre 0 e 1 definido pelo programador.</li>
    </ul>
    <h5>Quanto ao escopo:</h5>
    <ul>
        <li>Local: todo genótipo do filho é gerado a partir de 2 únicos pais</li>
        <li>Global: são selecionados 2 pais para cada gene do genótipo do filho</li>
    </ul>

    <h3>Delta (&delta;)</h3>
    <p>
        Fator de ponderação (não precisa preencher caso estiver usando crossover uniforme). Entre 0 e 1.
    </p>
    <h3>Mutation Operetor</h3>
    <ul>
        <li>Gaussian Perturbation: Usa uma perturbação gaussiana para mutar os indivíduos, da seguinte forma:
            Xi' = Xi + N(0, &sigma;'i), onde &sigma;'i é o i-ésimo elemento do vetor de desvios padrão mutado* do indivíduo que está sendo mutado.
        </li>
    </ul>
    <p>
        * Antes de cada mutação, uma o vetor de desvios padrão do indivíduo é mutado através da heurística escolhida
        no parâmetro <i>standard deviation change</i>
    </p>
    <figure>
        <figcaption>
            ** O desvio padrão de um genótipo também é chamado de <i>passo de mutação</i>, pois é ele quem define a amplitude dos valores
            que serão adicionados a cada elemento do genótipo.
        </figcaption>
        <img src="{% static 'imgs/gaussian.png' %}" alt="Standard deviation behaviour">
    </figure>
    <h3>Standard deviation change</h3>
    <p>
        Define a heurística que irá ser usada para mutacionar o vetor de desvios padrão de cada indivíduo. Pode ser:
    </p>
    <ul>
        <li>
            Success Rate: A cada mutação é verificado se o genótipo resultante é melhor do que o genótipo mutacionado. Em caso afirmativo
            uma unidade é adicionada a uma variável que acumula o número de mutações com sucesso. A partir daí, as novas mutações verificam a taxa
            mutações_com_sucesso/total_mutações e um valor aleatório <strong><i>c</i></strong> é sorteado entre 0.8 e 1. Com isso, três situações podem acontecer:
            <ol>
                <li>Se a taxa < 1/5, então &sigma;' = &sigma;/c (aumentar a amplitude de variação)</li>
                <li>Se a taxa > 1/5, então &sigma;' = &sigma; &#215; c (diminuir a amplitude de variação)</li>
                <li>Se a taxa = 1/5, então &sigma;' = &sigma; (mantém a amplitude atual)</li>
            </ol>
        </li>
        <li>
            Gaussian Multiple: &sigma;'i = &sigma;i &#215; N(0, &sigma;i)
        </li>
    </ul>

    <h3>Stop Condition</h3>
        <ul>
            <li>Number of iterations: a condição de parada será alcançada após o algoritmo gerar <i>N</i> gerações.</li>
            <li>
                Number of Draws: a condição de parada será alcançada após o algoritmo passar <i>N</i> gerações sem
                mudança de fitness.
            </li>
        </ul>

    <h3>Quantity</h3>
        <p>
            Define o valor <i>N</i>, citado na descrição do parâmetro anterior.
        </p>

    <h3>Chart: Mean fitness per generation</h3>
        <figure>
            <img src="{% static 'imgs/example_mean_generation.png' %}" style="height: 350px">
            <figcaption>
                Gráfico que mostra a média do fitness a cada geração.
            </figcaption>
        </figure>

    <h3>Chart: Lowest fitness per generation</h3>
        <figure>
            <img src="{% static 'imgs/example_lowest_generation.png' %}" style="height: 350px;">
            <figcaption>
                Gráfico que mostra o melhor fitness a cada geração.
            </figcaption>
        </figure>

    <h3>Chart: Fitness Incidence</h3>
        <figure>
            <img src="{% static 'imgs/example_fitness_incidende.png' %}" style="height: 350px;">
            <figcaption>
                Gráfico que mostra quantas vezes um valor de fitness foi repetido. Quanto maior o número de
                repetições, maior o raio do círculo. Os círculos podem ser vistos como mínimos em que
                as gerações ficaram presas. Quanto maior o círculo, mais tempo uma as gerações ficaram presas
                no mínimo que ele representa.
            </figcaption>
        </figure>

    <h3>Chart: Lowest fitness individual SD sum per generation</h3>
        <figure>
            <img src="{% static 'imgs/example_sd_sum.png' %}" style="height: 350px;">
            <figcaption>
                Gráfico que mostra a soma do vetor de desvios padrão do melhor indivíduo de cada geração.
            </figcaption>
        </figure>

    <h2>Comportamento do algoritmo de acordo com a seleção de parâmetros</h2>
        <p>
            <i>
                Todos os testes citados nesta seção têm as seguintes cosntantes em comum:
                <strong>Number of dimensions</strong> = 30, <strong>Mi size</strong> = 10,
                <strong>Lambda size</strong> = 70, <strong>Stop condition</strong> = Number
                of Iterations, <strong>Quantity</strong> = 100.
            </i>
        </p>
    <h3>Survivor selection</h3>
    <ul>
        <li><strong>&mu; + &lambda;</strong>: Pelo fato dessa estratégia de seleção de sobreviventes ser elitista/gulosa,
        o algoritmo tende a ficar mais presos em pontos que são ótimos locais e, portanto, não são a melhor solução</li>
        <li><strong>&mu;, &lambda;</strong>: A substituição da população pela sua prole a cada iteração do algoritmo, garante
        que a variedade de indivíduos nas populações seja uma constante. Isso facilita para escapar de prisões em pontos
        que são ótimos locais e convergir para o global.</li>
    </ul>
    <div class="row">
        <figure class="col-md-6 col-xs-12">
            <img src="{% static 'imgs/mi_plus_lambda_incidence.png' %}" style="height: 350px;">
            <figcaption>
                Com cem iterações, o melhor fitness alcançado foi em torno de 15, o que pode implicar uma
                taxa de convergência para um ponto que seja ótimo global muito lenta. Os pontos mostram que
                o algoritmo ficou preso por diversas vezes em ótimos locais.
            </figcaption>
        </figure>
        <figure class="col-md-6 col-xs-12">
            <img src="{% static 'imgs/mi_comma_lambda_incidence.png'%}" style="height: 350px;">
            <figcaption>
                Com cem iterações, o melhor fitness alcançado foi em torno de 6. A linha contínua mostra que,
                mesmo ficando por poucas iterações em alguns pontos ótimos locais, a substituição de gerações faz com
                que essa situação seja rapidamente driblada.
            </figcaption>
        </figure>
        <br><br>
        <p>
            <i>
                Como, dentre as duas opções, a que se mostrou melhor foi a &mu;, &lambda;, esta será deixada fixa para
                as próximas análises.
            </i>
        </p>
    </div>

    <h3>Crosssover Operator</h3>
    <ul>
        <li>
            <strong>Local</strong>:Como apenas dois pais são escolhidos para cruzar e gerar todos os genes do
            filho, a taxa de convergência é levemente menor do que a heurística global. Contudo, a execução
            do algoritmo é mais rápida.
        </li>
        <li>
            <strong>Global</strong>: O fato de escolher 2*(Number of dimensions) pais para gerar cada filho
            garante uma variade maior no genótipo e isso garante uma leve contribuição em casos em que é necessário
            sair de um ponto ótimo local. A convergência é mais rápida, contudo a execução é um pouco mais lenta.
        </li>
    </ul>
    <ul>
        <li>
            <strong>Intermediary</strong>: Quando o &delta; é diferente de zero, garante que todo gene tenha um percentual
            de características de cada pai que o gerou. Isso garante maior diversidade e apresenta uma maior taxa de convergência.
        </li>
        <li>
            <strong>Uniform</strong>: Equivalente à heurística Intermediary com &delta; igual a zero. Cada gene tem suas
            características provenientes de apenas um de seus pais (decidido aleatoriamente), o que faz com que a convergência
            se dê mais devagar do que a estratégia anterior.
        </li>
    </ul>
    <p><i>Portanto, a melhor heurística é Global Intermediary com &delta; diferente de zero (quanto mais próximo de 0.5, mais
        bem dividido será cada gene e, portanto, mais diversidade terá o genótipo).</i></p>

    <h3>Standard deviation change</h3>
    <ul>
        <li>
            <strong>Success Rate</strong>: A heurística de taxa de sucesso se mostra eficiente quando se trata de
            escapar de ótimos locais e manter uma boa taxa de convergência. Isso porque, enquanto a convergência estiver
            ocorrendo sem a ocorrência de o algoritmo ficar preso em ótimos locais, o vetor de desvios padrão tende a ficar
            semelhante aquele que "desencadeou" essa melhora. Em contrapartida, quando o algoritmo fica preso em um ótimo local,
            o vetor de desvios padrão sofre variadas perturbações afim de causar uma diversidade nos genótipos da população e, assim,
            escapar daquele ótimo.
        </li>
        <li>
            <strong>Gaussian Multiple</strong>: Apesar de ser uma heurísticca ótima para não ficar preso em ótimos locais,
            ela não é boa em "manter o foco" quando algo bom está acontecendo e isso dificulta a convergência para um ótimo
            global.
        </li>
    </ul>

    <h2>Conclusão</h2>
    <p>
        Como pode ser percebido através das análises feitas, o problema de otimização da função de Ackley é melhor
        e mais eficientemente resolvido através de uma estratégia evolutiva que pondere o elitismo e preserve a diversidade.
        Qualquer decrescimento desses dois fatores é facilmente notável, pois o desempenho do algoritmo piora rapidamente.
        Portanto, a melhor configuração para este problema é:
    </p>
    <ul>
        <li><strong>Survivor selection</strong> = &mu;, &lambda;</li>
        <li><strong>Mi size e lambda size</strong> = definidos de forma que &lambda; >> &mu; e, de preferência, com
            razão de 1 para 7.
        </li>
        <li><strong>Crossover Operator</strong> = Global Intermediary, com &delta; próximo de 0.5.</li>
        <li><strong>Standard deviation change</strong> = Success Rate.</li>
    </ul>
    <br><br>
{% endblock %}